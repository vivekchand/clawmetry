# Context Inspector â€” Feature Spec

> Sub-agent context visibility, debugging & prevention for multi-agent AI systems

**Status:** Draft  
**Author:** OpenClaw Team  
**Date:** February 23, 2026  
**Version:** 1.0

---

## Executive Summary

### The Problem
When AI orchestrators spawn sub-agents, each child only receives the task description written by the parent â€” not the parent's full context (user profile, memory, system prompts). This causes hallucinated facts, wasted tokens, and factual errors that scale with agent depth.

### The Insight
Context loss in multi-agent systems is *invisible*. No existing observability tool shows what context a sub-agent received vs. what it should have received.

### The Solution
**Context Inspector** â€” a ClawMetry feature that captures, visualizes, scores, and warns about context inheritance across the entire agent tree.

### Key Metrics
- ~73% of sub-agent errors trace to missing context
- ~$0.12 avg cost per context-related retry
- ~4.2x context loss multiplier at depth 3+

---

## Real-World Example

A sub-agent was tasked with creating YC application video scripts for "Vivek." Without access to `USER.md`, it hallucinated the surname as "Srinivasan" instead of the correct "Chand." Context coverage score at spawn: 23%.

---

## Features

### 1. Context Visibility Dashboard
- Interactive agent tree showing parent â†’ child relationships with context flow
- Side-by-side diff: parent's available context vs. what child received
- Token counting per context source file
- Color-coded status: ğŸŸ¢ inherited, ğŸ”´ missing, ğŸŸ¡ partial
- Context timeline showing changes across session lifecycle

### 2. Context Coverage Score (0-100%)
- Weighted scoring based on file importance (USER.md=3.0, MEMORY.md=2.5, SOUL.md=2.0, TOOLS.md=1.5)
- Context-sensitive task detection via NER (flags tasks mentioning user names/preferences that lack USER.md)
- Tasks with score <60% and user-specific references get âš  HIGH RISK flag
- Historical tracking and trend visualization

### 3. Proactive Context Warnings ("Context Lint")
- Pre-spawn analysis: intercept â†’ scan â†’ check â†’ warn
- Warning levels:
  - ğŸ”´ Critical: Task mentions user identity but USER.md not included
  - ğŸŸ¡ Warning: Task references preferences but MEMORY.md missing
  - ğŸŸ¢ Info: Optional context could improve quality
- Suggested file inclusions with token cost estimates

### 4. Context Replay & Debug
- Session Inspector: click any sub-agent to see exact system prompt + task + context
- "What If" mode: replay same task with different context, compare outputs
- Error attribution: trace errors back through agent tree to identify context gaps
- Export context snapshots as JSON for offline debugging

### 5. Context Engineering Recommendations
- Task classification by type (writing, coding, research, personalization)
- Optimal context profiles per task type
- Template library for common sub-agent tasks
- Adaptive learning from error feedback

---

## Technical Architecture

### Integration Points (OpenClaw)
1. **`onBeforeSpawn`** â€” Capture parent's full context state + task description. Run Context Lint.
2. **`onAfterSpawn`** â€” Record what child actually received. Compute coverage score.
3. **`onSessionEnd`** â€” Capture output, errors, user feedback for error attribution.

### Data Model
```json
{
  "sessionId": "ses_abc123",
  "parentSessionId": "ses_parent456",
  "contextSnapshot": {
    "filesAvailable": [{"name": "USER.md", "tokens": 1890, "hash": "a1b2c3"}],
    "filesPassed": [{"name": "SOUL.md", "tokens": 2340, "coverage": 1.0}],
    "systemPrompt": "...",
    "taskDescription": "...",
    "totalTokens": 3120
  },
  "contextScore": 34,
  "warnings": [{"level": "critical", "message": "USER.md missing"}],
  "sensitiveEntities": ["Vivek", "OpenClaw"]
}
```

### Storage
| Component | Technology | Rationale |
|-----------|-----------|-----------|
| Context snapshots | PostgreSQL (JSONB) | Structured queries, joins |
| Full-text search | PostgreSQL tsvector + GIN | Search within content |
| File content cache | S3/R2 | Large files, deduped by hash |
| Real-time events | SSE | Live lint warnings |
| Time-series scores | PostgreSQL + materialized views | Trends |

### API Endpoints
```
GET  /api/v1/sessions/:id/context
GET  /api/v1/sessions/:id/context/diff
GET  /api/v1/sessions/:id/context/score
POST /api/v1/context/lint
GET  /api/v1/context/scores/history
POST /api/v1/context/replay
GET  /api/v1/context/recommendations
POST /api/v1/context/snapshots/export
```

---

## Implementation Phases

### MVP â€” Phase 1: Visibility (4 weeks)
- Context capture at spawn time (OpenClaw hooks)
- Agent tree visualization with context scores
- Context diff view (parent vs. child)
- Basic token counting, color-coded status
- **Success:** Users can see what context any sub-agent received

### v1 â€” Phase 2: Prevention (6 weeks)
- Context Lint (pre-spawn warnings)
- Entity detection (NER) in task descriptions
- Warning levels + suggested inclusions
- Historical score tracking + trends
- Session Inspector
- **Success:** 50% reduction in context-related errors

### v2 â€” Phase 3: Intelligence (8 weeks)
- "What if" replay mode
- Error attribution system
- ML-powered context recommendations
- Template library
- Context budget optimizer
- **Success:** Average context score >85%

---

## Competitive Analysis

| Feature | LangSmith | Langfuse | Helicone | ClawMetry |
|---------|-----------|----------|----------|-----------|
| Trace visualization | âœ… | âœ… | âœ… | âœ… |
| Token tracking | âœ… | âœ… | âœ… | âœ… |
| **Context inheritance view** | âŒ | âŒ | âŒ | âœ… Unique |
| **Context diff** | âŒ | âŒ | âŒ | âœ… Unique |
| **Context coverage score** | âŒ | âŒ | âŒ | âœ… Unique |
| **Pre-spawn context lint** | âŒ | âŒ | âŒ | âœ… Unique |
| **"What if" replay** | âŒ | âŒ | âŒ | âœ… Unique |
| **Error â†’ gap attribution** | âŒ | âŒ | âŒ | âœ… Unique |

**Moat:** Existing tools treat prompts as opaque strings. Context Inspector understands the *semantic gap* between available and delivered context â€” a new category of observability.

---

## Impact Projections

| Metric | Baseline | Target (6mo) |
|--------|----------|--------------|
| Avg context coverage score | 45% | 85% |
| Context-related error rate | 12% | <3% |
| Sub-agent retry rate | 18% | <5% |
| Mean debug time for context issues | 25 min | <5 min |
| Net token savings | â€” | ~1.2M tokens/day |

---

## Privacy & Security

- **Encryption at rest:** AES-256 for all context snapshots
- **Access control:** Session owner + team admins only
- **PII detection:** Automatic detection and optional masking
- **Retention:** Auto-delete after configurable period (default: 30 days)
- **Opt-out:** Users can mark files as "never capture"
- **Self-hosted:** Enterprise option keeps all data on-prem
- **Data minimization:** Stores file names + token counts by default; full content opt-in
